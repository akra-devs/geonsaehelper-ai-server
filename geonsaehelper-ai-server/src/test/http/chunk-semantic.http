### Semantic chunking request example
# @timeout 6000
POST 127.0.0.1:8080/api/chunks/semantic
Content-Type: multipart/form-data; boundary=WebAppBoundary

--WebAppBoundary
Content-Disposition: form-data; name="file"; filename="HUG_POLICY.md"
Content-Type: text/markdown

< 전세사기피해자 최우선변제금 버팀목 전세자금 대출.MD
--WebAppBoundary
Content-Disposition: form-data; name="roleInstructions"

--WebAppBoundary
Content-Disposition: form-data; name="chunkSizeHint"

1000
--WebAppBoundary
Content-Disposition: form-data; name="maxChunkSize"

1200
--WebAppBoundary
Content-Disposition: form-data; name="mechanicalOverlap"

300
--WebAppBoundary--


### Semantic chunking + embeddings request example
# @timeout 1000000
POST http://localhost:8080/api/chunks/semantic/embed
Content-Type: multipart/form-data; boundary=WebAppBoundary

--WebAppBoundary
Content-Disposition: form-data; name="file"; filename="HUG_POLICY.md"
Content-Type: text/markdown

< 전세사기피해자 최우선변제금 버팀목 전세자금 대출.MD
--WebAppBoundary--
Content-Disposition: form-data; name="chunkSizeHint"

1000
--WebAppBoundary
Content-Disposition: form-data; name="maxChunkSize"

1200
--WebAppBoundary
Content-Disposition: form-data; name="mechanicalOverlap"

300
--WebAppBoundary--

### Embedding sample chunks (test controller)
GET http://localhost:8080/api/embeddings/test

### Direct Ollama call for semantic chunk block
POST http://localhost:11434/api/chat
Content-Type: application/json

{
  "model": "gpt-oss:20b",
  "stream": false,
  "messages": [
    {
      "role": "system",
      "content": "당신은 텍스트를 의미 단위로 분할하는 도우미입니다.\n- 출력은 JSON 배열 하나이며 각 요소는 텍스트 Chunk(String)입니다.\n- 청크는 입력 순서와 내용을 유지하고, 절대로 새로운 문장을 만들어내지 않습니다.\n- 기계적 분할에서 생긴 겹침 부분은 앞뒤 청크는 최소한만 조정하되, 그 외 원문 내용은 그대로 보존하세요.\n- 요청된 chunk_size_hint를 우선 적용하되 의미 단절을 피하기 위해 약간 짧거나 길어질 수 있습니다. max_chunk_size는 절대 초과하지 마세요.\n- 차이가 애매한 경계는 앞뒤 청크를 조금 잘라 명확하게 분리합니다.\n- JSON 외 다른 텍스트는 추가하지 마세요."
    },
    {
      "role": "user",
      "content": "{ \"block_index\": 0, \"chunk_size_hint\": 900, \"max_chunk_size\": 1200, \"text\": \"여기에 실험할 마크다운 청크 내용을 넣어주세요\" }"
    }
  ]
}

### Direct Ollama embeddings call
POST http://localhost:11434/api/embeddings
Content-Type: application/json

{
  "model": "embeddinggemma:300m",
  "input": [
    "임베딩 벡터를 생성할 텍스트를 여기에 넣어보세요."
  ]
}

### 123
POST http://localhost:8080/api/chunks/semantic/search
Content-Type: application/json

{
  "query": "전화번호"
}
###
POST http://localhost:6333/collections/geonsaehelper_embeddings/points/scroll
Content-Type: application/json

{
"limit": 10,
"with_payload": true,
"with_vector": false
}

###

